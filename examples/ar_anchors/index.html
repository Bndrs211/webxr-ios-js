<html>
	<head>
		<title>AR anchors example</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<script src="../libs/three.min.js"></script>
 		<script module src="../../dist/webxr.js"></script>
		<link rel="stylesheet" href="../common.css"/>
	</head>
	<body>
		<script>	
				window.hideMe = function(elem) { elem.style.display = 'none' }
		</script>
		<div onclick="hideMe(this)" id="description">
			<h2>Anchored Boxes</h2>
			<h5>(click to dismiss)</h5>
			<p>Anchor boxes to XRAnchors created in front the where the user taps on the screen.</p>
		</div>
		<button type=button id=go-button>Go</button>
		<script type=module>

			// some dependencies and utilities
			import * as mat4 from '../libs/gl-matrix/mat4.js'
			import * as vec3 from '../libs/gl-matrix/vec3.js'

			import XREngine from "../XREngine.js"
			import XRInputManager from "../XRInputManager.js"

			let device = null
			let session = null
			let headFrameOfReference = null
			let eyeLevelFrameOfReference = null
			let layer = null
			let frameOfReference = null
			let engine = null
			
			// temporary working variables
			const workingMatrix1 = mat4.create()
			const workingMatrix2 = mat4.create()
			const identity = mat4.identity(mat4.create())
			const upY = vec3.fromValues(0,1,0)

			// Create the output context where the XRSession will place composited renders
			const xrCanvas = document.createElement('canvas')
			xrCanvas.setAttribute('class', 'xr-canvas')
			const xrContext = xrCanvas.getContext('xrpresent')
			if(!xrContext){
				console.error('No XR context', xrCanvas)
			}


			// get the XR Device
			navigator.xr.requestDevice().then(xrDevice => {
				device = xrDevice
			}).catch(err => {
				console.error('Error', err)
			})

			document.getElementById('go-button').addEventListener('click', handleStartSessionRequest)

			// handle input events from the XRInputManager
			const inputManager = new XRInputManager(handleXRInput)
			function handleXRInput(eventName, details){
				switch(eventName){
					case 'normalized-touch':
						addAnchorInScreenCoordinates(...details.normalizedCoordinates)
						break
					default:
						console.error('unknown xr input event', eventName, details)
						break
				}
			}

			function addAnchorInScreenCoordinates(normalizedX, normalizedY){
				if(session === null){
					console.log('No session for adding anchor')
					return
				}
				if(headFrameOfReference === null){
					console.log('No frame of reference')
					return 
				}
				// Convert the screen coordinates into head-model origin/direction for hit testing
				const [origin, direction] = XRInputManager.convertScreenCoordinatesToRay(normalizedX, normalizedY, 
																							engine.camera.projectionMatrix)

				// set up the local transformation to be positioned relative to the camera along
				// the ray, but also oriented along the ray direction
				mat4.targetTo(workingMatrix1, origin, direction, upY)
				mat4.fromTranslation(workingMatrix2, direction)
				mat4.multiply(workingMatrix1, workingMatrix2, workingMatrix1)

				// create an anchor in front of the phone
				session.addAnchor(workingMatrix1, headFrameOfReference).then(anchor => {					
					engine.addAnchoredNode(anchor, createSceneGraphNode())					
				}).catch(err => {
					console.error('Error adding anchor', err)
				})

			}

			// Creates a box used to indicate the location of an anchor offset
			function createSceneGraphNode(){
				let group = new THREE.Group()
				let geometry = new THREE.BoxBufferGeometry(0.1, 0.1, 0.1)
				var color = new THREE.Color( 0xffffff );
        		color.setHex( Math.random() * 0xffffff );
				let material = new THREE.MeshPhongMaterial({ color: color })
				let mesh = new THREE.Mesh(geometry, material)
	
				var outlineMaterial = new THREE.MeshBasicMaterial( { color: 0x00ff00, side: THREE.BackSide } );
				var outlineMesh = new THREE.Mesh( geometry, outlineMaterial );

				mesh.position.set(0, 0.05, 0)
				outlineMesh.position.set(0, 0.05, 0);
				outlineMesh.scale.multiplyScalar(1.05);

				group.add(mesh)
				group.add(outlineMesh)
				return group
			}

			/////////////////////
			// Session startup / shutdown
			function handleStartSessionRequest(ev){
				if(device === null){
					console.error('No xr device')
					return
				}

				if (!session) {
					device.requestSession({ outputContext: xrContext })
						.then(handleSessionStarted)
						.catch(err => {
							console.error('Session setup error', err)
						})
					document.getElementById('go-button').text = "End"
				} else {
					session.end()
					handleSessionEnded();
					document.getElementById('go-button').text = "Go"
				}
			}

			function handleSessionEnded() {	
				session = null
			}

			function handleSessionStarted(xrSession){
				session = xrSession
				document.body.insertBefore(xrCanvas, document.body.firstChild)

				// Create the context where we will render our 3D scene
				const canvas = document.createElement('canvas')
				var glContext = canvas.getContext('webgl', {
					compatibleXRDevice: device
				})
				if(!glContext) throw new Error('Could not create a webgl context')

				// Set up the base layer
				session.baseLayer = new XRWebGLLayer(session, glContext)

				// Create a simple test scene and renderer
				// The engine's scene is in the eye-level coordinate system 
				engine = new XREngine(canvas, glContext)
				engine.addAmbientLight()
				engine.addDirectionalLight()

				// Add a box and sphere at the origin of the eye-level coordinate system
				engine.addBox([0, 0, 0], [0.025, 0.025, 0.025], 0x44ff44)
				engine.addAxesHelper([0,0,0], [0.2,0.2,0.2])				

				// head-model is the coordinate system that tracks the position of the display
				session.requestFrameOfReference('head-model').then(frameOfReference =>{
					headFrameOfReference = frameOfReference
				})
				.catch(err => {
					console.error('Error finding head frame of reference', err)
				})
				// eye-level is the coordinate system of the ARKit tracking system 
				session.requestFrameOfReference('eye-level').then(frameOfReference => {
					eyeLevelFrameOfReference = frameOfReference
					// Kick off rendering
					session.requestAnimationFrame(handleAnimationFrame)
				})
				.catch(err => {
					console.error('Error finding eye frame of reference', err)
				})
			}

			////////////////
			// render loop			
			function handleAnimationFrame(t, frame){
				if(session.ended) return
				session.requestAnimationFrame(handleAnimationFrame)

				let pose = frame.getDevicePose(eyeLevelFrameOfReference)
				if(!pose){
					console.log('No pose')
					return
				}

				engine.startFrame()
				for (let view of frame.views) {
					engine.render(
						session.baseLayer.getViewport(view),
						view.projectionMatrix,
						pose.getViewMatrix(view)
					)
					break
				}
				engine.endFrame()
			}

		</script>
	</body>
</html>