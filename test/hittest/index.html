<html>
	<head>
		<meta charset="utf-8">
		<script src="../libs/three/three.min.js"></script>
<!-- 		<script module src="../../dist/webxr.js"></script>
 -->		<style>
			button {
				font-size: 16px;
			}
			html, 
			body, 
			.xr-canvas,
			.arkit-device-wrapper, 
			.arkit-device-wrapper canvas {
				width: 100%;
				height: 100%;
				padding: 0;
				margin: 0;
			}
			body {
				z-index: 1;
			}
			.arkit-device-wrapper, .xr-canvas {
				position: absolute;
				top: 0;
				left: 0;
				bottom: 0;
				right: 0;
			}
			.arkit-device-wrapper {
				z-index: -1;
			}
			.xr-canvas {
				z-index: -2;
			}
			#go-button { margin: 20px; }
		</style>
	</head>
	<body>
		<button type=button id=go-button>Go</button>
		<script type=module>
			import * as mat4 from '/test/libs/gl-matrix/mat4.js'
			import * as vec3 from '/test/libs/gl-matrix/vec3.js'

			import XREngine from "./XREngine.js"
			import XRInputManager from "./XRInputManager.js"

			let device = null
			let session = null
			let headFrameOfReference = null
			let eyeLevelFrameOfReference = null
			let layer = null
			let frameOfReference = null
			let engine = null
			
			const workingMatrix1 = mat4.create()
			const identity = mat4.identity(mat4.create())

			const inputManager = new XRInputManager(handleXRInput)

			// Create the output context where the XRSession will place composited renders
			const xrCanvas = document.createElement('canvas')
			xrCanvas.setAttribute('class', 'xr-canvas')
			const xrContext = xrCanvas.getContext('xrpresent')
			if(!xrContext){
				console.error('No XR context', xrCanvas)
			}

			navigator.xr.requestDevice().then(xrDevice => {
				device = xrDevice
			}).catch(err => {
				console.error('Error', err)
			})

			document.getElementById('go-button').addEventListener('click', handleStartSessionRequest)

			// handle input events from the XRInputManager
			function handleXRInput(eventName, details){
				switch(eventName){
					case 'normalized-touch':
						hitTestWithScreenCoordinates(...details.normalizedCoordinates)
							.then(handleHitResults)
							.catch(err => {
								console.error('Error testing hits', err)
							})
						break
					default:
						console.error('unknown xr input event', eventName, details)
						break
				}
			}

			function hitTestWithScreenCoordinates(normalizedX, normalizedY){
				if(session === null){
					console.log('No session for hit testing')
					return Promise.reject()
				}
				if(headFrameOfReference === null){
					console.log('No frame of reference')
					return Promise.reject()
				}
				// Convert the screen coordinates into head-model origin/direction for hit testing
				const [origin, direction] = XRInputManager.convertScreenCoordinatesToRay(normalizedX, normalizedY, 
													    								 engine.camera.projectionMatrix)

				/*
				// Add a box at the origin
				const csTransform = headFrameOfReference.getTransformTo(eyeLevelFrameOfReference)
				mat4.multiply(workingMatrix1, mat4.fromTranslation(mat4.create(), [origin[0], origin[1], 0]), csTransform)
				engine.addBox([workingMatrix1[12], workingMatrix1[13], workingMatrix1[14]], [0.01, 0.01, 0.01], 0xffff66)
				*/
				console.log('normalized', normalizedX, normalizedY)
				return session.requestHitTest(origin, direction, headFrameOfReference)
			}

			function handleHitResults(hits) {
				let size = 0.05;
				for(let hit of hits){
					// TODO ONLY use one hit result to create a box!

					// convert hit matrices from head to eye level coordinate systems
					const csTransform = headFrameOfReference.getTransformTo(eyeLevelFrameOfReference)
					mat4.multiply(workingMatrix1, hit.hitMatrix, csTransform)

					// get an offset based on Y vec in the matrix transform, and size of cube
					let offset = [workingMatrix1[1] * size * 0.5, workingMatrix1[5] * size * 0.5, workingMatrix1[9] * size * 0.5]

					// show a box at the hit
					engine.addBox([workingMatrix1[12] + offset[0], workingMatrix1[13]  + offset[1], workingMatrix1[14] + offset[2]], 
								  [size, size, size], 0xff4444)
					console.log('box transform', mat4.getTranslation(vec3.create(), workingMatrix1), mat4.getRotation(new Float32Array(4), workingMatrix1), offset)
				}
			}

			function handleStartSessionRequest(ev){
				if(device === null){
					console.error('No xr device')
					return
				}

				device.requestSession({ outputContext: xrContext })
					.then(handleSessionStarted)
					.catch(err => {
						console.error('Session setup error', err)
					})
			}

			function handleSessionStarted(xrSession){
				session = xrSession
				document.body.insertBefore(xrCanvas, document.body.firstChild)

				// Create the context where we will render our 3D scene
				const canvas = document.createElement('canvas')
				var glContext = canvas.getContext('webgl', {
					compatibleXRDevice: device
				})
				if(!glContext) throw new Error('Could not create a webgl context')

				// Set up the base layer
				session.baseLayer = new XRWebGLLayer(session, glContext)

				// Create a simple test scene and renderer
				// The engine's scene is in the eye-level coordinate system 
				engine = new XREngine(canvas, glContext)
				engine.addAmbientLight()
				engine.addDirectionalLight()
				// Add a box and sphere at the origin of the eye-level coordinate system
				engine.addBox([0, 0, 0], [0.005, 0.0025, 0.025], 0x44ff44)
				engine.addSphere([0, 0, -0.025], [0.0025, 0.0025, 0.0025], 0xff4444)

				// head-model is the coordinate system that tracks the position of the display
				session.requestFrameOfReference('head-model').then(frameOfReference =>{
					headFrameOfReference = frameOfReference
				})
				.catch(err => {
					console.error('Error finding head frame of reference', err)
				})
				// eye-level is the coordinate system of the ARKit tracking system 
				session.requestFrameOfReference('eye-level').then(frameOfReference => {
					eyeLevelFrameOfReference = frameOfReference
					// Kick off rendering
					session.requestAnimationFrame(handleAnimationFrame)
				})
				.catch(err => {
					console.error('Error finding eye frame of reference', err)
				})
			}

			function handleAnimationFrame(t, frame){
				if(session.ended) return
				session.requestAnimationFrame(handleAnimationFrame)

				let pose = frame.getDevicePose(eyeLevelFrameOfReference)
				if(!pose){
					console.log('No pose')
					return
				}

				engine.startFrame()
				for (let view of frame.views) {
					engine.render(
						session.baseLayer.getViewport(view),
						view.projectionMatrix,
						pose.getViewMatrix(view)
					)
					break
				}
				engine.endFrame()
			}

		</script>
	</body>
</html>